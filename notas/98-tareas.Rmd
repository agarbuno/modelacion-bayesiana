# Tareas {-}

```{r setup, include=FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
library(scales)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())
color.blues <- c(NA,"#BDD7E7", "#6BAED6", "#3182BD", "#08519C", "#074789", "#063e77", "#053464")
color.itam  <- c("#00362b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f")


sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
sin_leyenda <- theme(legend.position = "none")
sin_ejes <- theme(axis.ticks = element_blank(), 
        axis.text = element_blank())
```

## Integración Monte Carlo y Cadenas de Markov {-}

1. Utiliza el método Monte Carlo para aproximar 
$$\int_1^2 \frac{e^{-x^2/2}}{\sqrt{2 \pi}} \, \text{d}x \, .$$
*Hint: * reescribe la integral en términos de un problema de integración con
respecto a una densidad $\pi(x)$ y una función resumen $f(x).$

1. Marginalización Monte Carlo es una técnica para calcular densidades 
marginales cuando simulamos de una densidad conjunta. Sea $\pi(x,y)$ una
densidad conjunta y sea $\pi(x) = \int \pi(x, y) \text{d} y \,,$ la densidad
marginal de $x.$ 
    
    - Sea $w(x)$ una densidad arbitraria. Prueba que $$\int \int
    \frac{\pi(x^\star, y) w(x)}{\pi(x, y)} \, \pi(x, y) \,\text{d}x\, \text{d}y
    \, = \pi(x^\star)\,.$$
    
    - Argumenta cómo podríamos utilizar la formulación de arriba para constuir un 
    estimador Monte Carlo de la densidad marginal. 
    
    - En el contexto de los puntos anteriores, sean $x|y \sim \mathsf{Gamma}(y,
    1)$ y $y \sim \mathsf{Exp}(1).$ Utiliza la técnica de arriba para calcular
    la densidad marginal de x.

2. Implementa el método Metropolis para muestrear de una
$\mathsf{Poisson}(\lambda).$ Prueba con $\lambda = 3, 5,$ y $10.$ Para la 
distribución de propuesta utiliza una caminata aleatoria sobre los enteros.
*Hint: * recuerda lo que hicimos con las islas del vendedor.

2. Sea $X \sim \mathsf{N}(0,1).$ Implementa el método Metropolis para generar
muestras de $X.$ Como distribución de propuesta utiliza una normal con varianza 
igual a $\sigma^2.$ Prueba varios valores para $\sigma.$ Como caso particular
considera $\sigma = 2.38,$ ¿cómo se compara la tasa de aceptación y las
trayectorias con estos distintos valores?

3. Modelo logístico. (*Tomado de* @robertCasella). Este ejercicio considera 
la situación del lanzamiento del Challenger en 1986. La explosión se originó 
por la falla de un anillo que sella ciertos componentes de la nave espacial.
Se cree que el accidente se originó por las bajas temperaturas al momento de 
lanzamiento. Y se considera que la probabilidad de falla aumenta cuando la 
temperatura decrece. 
Se tienen datos históricos
```{r, echo = FALSE}
datos <- tibble(falla = c(1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,1, 
                          0, 0, 0, 0, 0), 
                temperatura = c(53, 57, 58, 63, 66, 67, 67, 67, 68, 69, 70, 70, 
                                70, 70, 72, 73, 75, 75, 76, 76, 78, 79, 81)) %>% 
     mutate( temperatura = (temperatura - 32) * 5/9)

datos %>% head()
```
    
y se modela la probabilidad de falla como 
$$\mathbb{P}(Y = 1 | X ) = p(X) = \frac{\exp(\alpha + \beta X)}{1 + \exp(\alpha + \beta X)} \, .$$

Consideramos la muestra como observaciones 
$$Y_i \sim \mathsf{Bernoulli}(p(X_i))\,,$$
con distribución previa de la forma
$$\pi(\alpha, \beta) = \pi(\alpha |\beta) \, \pi(\beta) \propto \frac1b e^\alpha \exp\left(-\frac{e^\alpha}{b}\right) \,,$$
donde se asume $\log \alpha \sim \mathsf{Exp}(b),$ y una distribución
proporcional a una constante para $\beta.$


