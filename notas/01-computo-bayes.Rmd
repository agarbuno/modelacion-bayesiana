\mainmatter

# Cómputo probabilístico

```{r setup, include=FALSE, message=FALSE}
library(tidyverse)
library(patchwork)
library(scales)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())
color.blues <- c(NA,"#BDD7E7", "#6BAED6", "#3182BD", "#08519C", "#074789", "#063e77", "#053464")
sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
sin_leyenda <- theme(legend.position = "none")
sin_ejes <- theme(axis.ticks = element_blank(), 
        axis.text = element_blank())
```

Las notas para este curso difieren de las presentadas originalmente en
[EST-46111](https://fundamentos-est.netlify.app/) en Otoño 2020. En particular,
la discusión teórica está basada en las notas del curso en Problemas Inversos y
Asimilación de Datos [@inverse-problems].

Hasta ahora, hemos considerado modelos bayesianos *conjugados*, donde la
posterior tiene una forma conocida. Esto nos permitió simular directamente
de la posterior usando generadores estándar de números aleatorios (por ejemplo,
variables aleatorias normales, Gamma, Poisson, Binomial Negativa, etc.) Por otro
lado, en algunas situaciones pudimos utilizar cálculos teóricos o funciones
estándar de `R` para calcular resúmenes de interés, como medias o medianas
posteriores o intervalos de credibilidad. 

```{block, type = 'ejercicio'}

Escribe el modelo conjugado Poisson-Gamma. Determina los valores posteriores de
los parámetros. Escribe los valores de media y varianza. Identifica las
funciones estándar que utilizarías para calcular los parámetros dada una
muestra.

```


Sin embargo, en aplicaciones rara vez es factible este tipo de análisis tan
simple, pues:

1. Los modelos que estamos considerando son más complejos y la distribución
posterior conjunta de los parámetros no tiene una forma simple conocida.
2. Queremos usar distribuciones iniciales que no son conjugadas para utilizar
correctamente nuestra información inicial.

## Integración por discretización {-}

Recordamos que tenemos expresiones explícitas para la inicial $p(\theta)$ y la
verosimilitud $p(x|\theta)$, así que conocemos parcialmente la posterior,
módulo la constante de normalización,

$$p(\theta|x) \propto p(x|\theta) \,\,  p(\theta).$$

En general nos interesa reportar resúmenes de nuestras distribuciones (¿por
qué?). Esto quiere decir, identificamos una función resumen y promediamos dicha
función de acuerdo a los pesos que la distribución posterior asigna. Es decir,

$$ \mathbb{E}[f] = \int_\Theta f(\theta) \,\, p(\theta|x) \,\, \text{d}\theta, $$

donde $f$ es la función resumen, y $\Theta$ el soporte de la distribución
$p(\cdot \, | x).$ Supongamos por ejemplo que quisiéramos calcular la media
posterior de $\theta \in \mathbb{R}.$

Lo que tenemos que hacer es calcular la integral

$$\hat \theta = \mathbb{E}[{\theta}\, |\, x] = \int_\Theta \theta \, p(\theta|x) \, \text{d}\theta.$$
Analiticamente necesitamos saber $p(\theta|x)$ para cualquier valor de $\theta$
de forma cerrada. Esto implica conocer la constante de normalización $p(x)$, que
resulta de la integral

$$p(x) = \int p(x|\theta) \, p(\theta)\, \text{d}\theta.$$

```{block, type = 'ejercicio'}

Considera una variable aleatoria uniforme $v \sim \textsf{U}[a, b].$ Calcula la
media y varianza de dicha variable aleatoria. Identifica la función de densidad
$p(v),$ y las funciones resumen $f$ para cada caso. ¿Puedes identificar la
constante de normalización?

```

En general, si no tenemos expresiones analíticas simples, tendremos que
aproximar numéricamente estas integrales de alguna forma. El candidato _natural_
para efectuar la aproximación es utilizar la definición de integral. Es decir,
dividir el espacio en intervalos $\{u_1, \ldots, u_n\}$ por medio de una malla de
$N+1$ puntos, $\{x_0, \ldots, x_N\},$ tal que

$$ \mathbb{E}[f] \approx \sum_{n=1}^N f(u_n) \, p(u_n) \, \Delta u_n,$$

donde $\Delta u_n$ denota la precisión de la malla y el valor del integrando
$f(u_n) \, p(u_n)$ se asigna de acuerdo a la regla de intregación. A estos
métodos se les conoce como reglas de *cuadratura*. Los valores $N, x_n, \Delta
u_n$ se asignan de acuerdo a cierta tolerancia, la función de peso y la regla de
interpolación.

```{r}
grid.n <- 11
grid.size <- 6/(grid.n+1)
norm.cuadrature <- tibble(x = seq(-3, 3, by = grid.size), y = dnorm(x) )

```


```{r, echo = FALSE, out.width = "95%"}

norm.density <- tibble(x = seq(-5, 5, by = .01), 
       y = dnorm(x) ) 
  
norm.cuadrature %>% 
  ggplot(aes(x=x + grid.size/2, y=y)) + 
    geom_area(data = norm.density, aes(x = x, y = y), fill = 'lightblue') + 
    geom_bar(stat="identity", alpha = .3) + 
    geom_bar(aes(x = x + grid.size/2, y = -0.01), fill = 'black', stat="identity") + 
    sin_lineas + xlab('x') + 
    annotate('text', label = expression(Delta~u[n]), x = .01 + 5 * grid.size/2, y = -.02) + 
    annotate('text', label = expression(f(u[n]) * p(u[n]) ), x = .01 + 9 * grid.size/2, y = dnorm(.01 + 4 * grid.size/2)) + 
    annotate('text', label = expression(f(u[n]) * p(u[n]) * Delta~u[n]), 
             x = .01 + 5 * grid.size/2, y = dnorm(.01 + 4 * grid.size/2)/2, 
             angle = -90, alpha = .7)
  

```

La aproximación en este caso es

```{r, echo = FALSE}
norm.cuadrature %>% 
  summarise(approx = sum(y * grid.size), N = n()) %>% 
  round(5)
```

Las rutinas usuales de integración pueden sernos útiles cuando el número de
parámetros es chico. En el caso anterior tenemos una buena aproximación con $N=
17$ evaluaciones del integrando. 


### Ejemplo: estimación de una proporción {-}

Supongamos que $p(S_n = k|\theta) \propto \theta^k(1-\theta)^{n-k}$ cuando
observamos $k$ éxitos en $n$ pruebas independientes. Supongamos que nuestra
inicial es $p(\theta) = 2\theta$ (checa que es una densidad), es decir, creemos
que es más probable a priori observar proporciones altas. Podemos integrar
numéricamente

```{r}
crear_log_post <- function(n, k){
  function(theta){
    verosim <- k * log(theta) + (n - k) * log(1 - theta)
    inicial <- log(theta)
    log_p_factor <- verosim + inicial
    log_p_factor
  }
}
# observamos 3 éxitos en 4 pruebas:
log_post <- crear_log_post(4, 3)
prob_post <- function(x) { exp(log_post(x))}
# integramos numéricamente
p_x <- integrate(prob_post, lower = 0, upper = 1, subdivisions = 100L)
p_x
```

Y ahora podemos calcular la media posterior:

```{r}
media_funcion <- function(theta){
  theta * prob_post(theta) / p_x$value
}
integral_media <- integrate(media_funcion, lower = 0, upper = 1, subdivisions = 100L)
media_post <- integral_media$value 
media_post
```

Podemos verificar nuestro trabajo pues sabemos que la posterior es
$\mathsf{Beta}(5, 2)$ cuya media es

```{r}
5/(2+5)
```

### Más de un parámetro {-}

Ahora supongamos que tenemos $2$ parámetros. Es decir, $\theta \in
\mathbb{R}^2.$ Los intervalos se vuelven regiones rectangulares. Si cada 
dimensión es discretizada utilizando $N$ puntos, entonces en total tendremos 
$N^2$ puntos donde deberíamos evaluar el integrando.

```{r, echo = FALSE, out.width  = "99%"}
# Codigo utilizado: 
# https://stackoverflow.com/questions/17521438/geom-rect-and-alpha-does-this-work-with-hard-coded-values

m <- ggplot(faithful, aes(x = eruptions, y = waiting)) +
 xlim(0.5, 6) +
 ylim(40, 110)

grid.size <- 10 - 1

mesh <- expand.grid(x = seq(0.5, 6, by = (6-.5)/grid.size), y = seq(40, 110, by = (110-40)/grid.size))

m + geom_density_2d_filled(aes(alpha = ..level..), bins = 8) + 
  scale_fill_manual(values = color.blues) + 
  sin_lineas + theme(legend.position = "none")  + 
  geom_point(data = mesh, aes(x = x, y = y)) + 
  annotate("rect", xmin = .5 + 5 * (6-.5)/grid.size, 
            xmax = .5 + 6 * (6-.5)/grid.size, 
            ymin = 40 + 3 * (110-40)/grid.size, 
            ymax = 40 + 4 * (110-40)/grid.size,
            linestyle = 'dashed', 
           fill = 'salmon', alpha = .4) + ylab("") + xlab("") + 
  annotate('text', x = .5 + 5.5 * (6-.5)/grid.size, 
                   y = 40 + 3.5 * (110-40)/grid.size, 
           label = expression(u[n]), color = 'red') +
  theme(axis.ticks = element_blank(), 
        axis.text = element_blank())

```


Generalizando, si tenemos $p$ parámetros, entonces bajo un esquema
discretización uniforme tendríamos que hacer $N^p$ evaluaciones del integrando.
Por ejemplo, si $p=10$ **esta estrategia es infactible**, pues tendríamos que
hacer más de millones de millones de millones de evaluaciones de la posterior.
Si sólo tenemos esta técnica disponible, el análisis bayesiano está
considerablemente restringido. Regresión bayesiana con unas 10 covariables por
ejemplo, no podría hacerse.

Los errores del método de cuadratura están ligadas a la estrategia de
discretización, el número de elementos, y las reglas de interpolación. En
general, no habrá poder computacional suficiente para realizar integrales en
dimensiones elevadas. Por lo que tendremos que *asignar nuestros recursos
computacionales limitados* de forma inteligente y *donde tengamos mayor
impacto.*

Los métodos que estudiaremos en esta sección se enfocarán en presentar
alternativas para poder aproximar estas integrales.

## Integración Monte Carlo {-}

Anteriormente  hemos usado el método Monte Carlo para aproximar integrales: por
ejemplo, para calcular medias posteriores. En general, calculamos el valor
esperado de un resumen, y lo escribimos como

$$\mathbb{E}_\pi[f] = \pi(f) = \int f(x) \pi(x) \text{d}x,$$

donde $f(x)$ es la función de interés y $\pi(x)$ es la función de densidad de la
variable aleatoria $x.$ Lo que hemos hecho anteriormente es generar muestras 
independientes del modelo de probabilidad y promediar $f$ evaluada en cada uno 
de los puntos generados. Esto es, generamos $x^{(n)} \sim \pi(x)$ de manera
independiente para $n = 1, \ldots, N,$ y escribimos nuestro estimador como

$$\pi_N^{\textsf{MC}}(f) = \frac1N \sum_{n = 1}^N f( x^{(n)}).$$

**Nota:** Aunque $\pi(x)$ denota una densidad, $\pi(f)$ denota un objeto
completamente distinto. Esto es, el promedio de $f$ bajo la densidad $\pi.$

Podemos utilizar el método Monte Carlo para aproximar el valor de $\pi.$
Consideremos el experimento de lanzar dardos uniformemente en un cuadrado de
tamaño 2, el cual contiene un circulo de radio 1. Distintas realizaciones se
muestran abajo con distintos valores de número de lanzamientos $10^k$ con $k =
2, 3, 4, 5.$

```{r, echo = FALSE, out.width = "99%", fig.height = 2}

genera_dardos <- function(n = 100){
  tibble(x1 = runif(n, min = -1, max = 1), 
         x2 = runif(n, min = -1, max = 1)) %>% 
    mutate(resultado = ifelse(x1**2 + x2**2 <= 1., 1., 0.))
}

dardos <- tibble(n = seq(2,5)) %>% 
  mutate(datos = map(10**n, genera_dardos)) %>% 
  unnest() 

dardos %>% 
  ggplot(aes(x = x1, y = x2)) + 
    geom_point(aes(color = factor(resultado))) + 
    facet_wrap(~n, nrow = 1) + 
    sin_lineas + sin_ejes + sin_leyenda

```

Podemos graficar la aproximación del método Monte Carlo, y observarmos un 
comportamiento que debería de ser familiar para nosotros. ¿Cómo le llamaríamos 
a nuestro estimador $\pi_N^{\textsf{MC}}(f)?$

```{r, cache = TRUE, out.width = "99%", fig.height = 3, echo = FALSE}
set.seed(1087)

genera_dardos(n = 2**16) %>% 
  mutate(n = seq(1, 2**16), 
         approx = cummean(resultado) * 4) %>% 
  ggplot(aes(x = n, y = approx)) + 
    geom_line() + 
    geom_hline(yintercept = pi, linetype = 'dashed') + 
    scale_x_continuous(trans='log10', 
                       labels = trans_format("log10", math_format(10^.x))) + 
    ylab('Aproximación') + xlab("Muestras") + sin_lineas
  

```

Este comportamiento no es particular del caso anterior. Se extiende para una familia
mas amplia de problemas bajo ciertas condiciones de regularidad. El resultado lo
expresamos en el teorema siguiente.

```{block, type = 'mathblock'}

**Teorema (Error Monte Carlo).** Sea $f : \mathbb{R}^p \rightarrow \mathbb{R}$
cualquier función *bien comportada*$^\dagger.$ Entonces, el estimador Monte Carlo es
**insesgado**

$$\mathbb{E}\left[ \pi_N^{\textsf{MC}}(f) - \pi(f)\right] = 0,$$

y tiene **error cuadrático medio acotado**

$$ \sup_{f \in \mathcal{F}} \, \,  \mathbb{E}\left[ \left(\pi_N^{\textsf{MC}}(f) - \pi(f) \right)^2 \right] \leq \frac1N.$$

```

En particular, la varianza del estimador (**error estándar**) satisface la igualdad

$$ \textsf{ee}^2\left(\pi_N^{\textsf{MC}}(f)\right) = \frac{\mathbb{V_\pi(f)}}{N}.$$

De tal forma que se satisface el siguiente teorema. 

```{block, type = 'mathblock'}

**Teorema (TLC para estimadores Monte Carlo).** Sea $f$ una función *bien
comportada*$^{\dagger\dagger},$ entonces 

$$ \frac{\pi_N^{\textsf{MC}}(f) - \pi(f)}{\mathbb{V}_\pi(f)} \sim \mathsf{N}\left(0, \,\, \frac{1}{\sqrt{N}}\right).$$

```

**Nota:** la cota en la varianza del estimador no depende en la dimensión del 
problema. Sólo depende del número de simulaciones que hacemos del modelo. Esto, 
en principio, hace del método Monte Carlo un método escalable aún para
problemas de un número elevado de parámetros.

### Ejemplo: proporciones {-}

Consideramos la estimación de una proporción $\theta,$ tenemos como inicial
$p(\theta) \propto \theta$, que es una $\mathsf{Beta}(2,1)$. Si observamos 3
éxitos en 4 pruebas, entonces sabemos que la posterior es $p(\theta|x)\propto
\theta^4(1-\theta)$, que es una $\mathsf{Beta}(5, 2)$. Si queremos calcular la
media y el segundo momento posterior para $\theta$, en teoría necesitamos
calcular

$$\mu = \int_0^1 \theta \,\, p(\theta|X = 3)\, \text{d}\theta,\qquad  \mu_2=\int_0^1 \theta^2 \,\, p(\theta|X = 3)\, \text{d}\theta.$$

Podemos integrar utilizando el método Monte Carlo

```{r}
theta <- rbeta(10000, 5, 2)
media_post <- mean(theta)
momento_2_post <- mean(theta^2)
c(media_post, momento_2_post)
```

Y podemos aproximar de esta manera cualquier cantidad de interés que esté basada
en integrales, como probabilidades asociadas a $\theta$ o cuantiles asociados.
Por ejemplo, podemos aproximar fácilmente $P(e^{\theta}> 2|x)$ haciendo

```{r}
mean(exp(theta) > 2)
```

y así sucesivamente. 

### Ejemplo: pruebas independientes {-}

Supongamos que probamos el nivel de gusto para 4 sabores distintos de una
paleta. Usamos 4 muestras de aproximadamente 50 personas diferentes para cada
sabor, y cada uno evalúa si le gustó mucho o no. Obtenemos los siguientes
resultados:

```{r}
datos <- tibble(
  sabor = c("fresa", "limón", "mango", "guanábana"),
  n = c(50, 45, 51, 50), gusto = c(36, 35, 42, 29)) %>% 
  mutate(prop_gust = gusto / n)
datos
```

Usaremos como inicial $\mathsf{Beta}(2, 1)$ (pues hemos obervado cierto sesgo de
cortesía en la calificación de sabores, y no es tan probable tener valores muy
bajos) para todos los sabores, es decir $p(\theta_i)$ es la funcion de densidad
de una $\mathsf{Beta}(2, 1)$. La inicial conjunta la definimos entonces, usando
idependiencia inicial, como

$$p(\theta_1,\theta_2, \theta_3,\theta_4) = p(\theta_1)p(\theta_2)p(\theta_3)p(\theta_4).$$
Pues inicialmente establecemos que ningún parámetro da información sobre otro:
saber que mango es muy gustado no nos dice nada acerca del gusto por fresa. Bajo
este supuesto, y el supuesto adicional de que las muestras de cada sabor son
independientes, podemos mostrar que las posteriores son independientes:

$$p(\theta_1,\theta_2,\theta_3, \theta_4|k_1,k_2,k_3,k_4) = p(\theta_4|k_1)p(\theta_4|k_2)p(\theta_4|k_3)p(\theta_4|k_4)$$

De forma que podemos trabajar individualmente con cada muestra. Calculamos los
parámetros de las posteriores individuales:

```{r}
datos <- datos %>% 
  mutate(a_post = gusto + 2, b_post = n - gusto + 1)
datos
```

Ahora nos preguntamos, ¿cuál es la probabilidad posterior de que mango sea el sabor 
más preferido de la población? Conocemos la posterior para cada parámetro, y sabemos
que los parámetros son independientes para la posterior. Eso quiere decir
que podemos simular de cada parámetro independientemente para obtener simulaciones
de la conjunta posterior.

```{r, cache = TRUE}
simular_conjunta <- function(rep, datos){
  datos %>% mutate(valor_sim = map2_dbl(a_post, b_post, ~ rbeta(1, .x, .y))) %>% 
    select(sabor, valor_sim) 
}
simular_conjunta(1, datos) 
```

```{r}
# esta no es una manera muy rápida, podríamos calcular todas las
# simulaciones de cada parámetro de manera vectorizada
sims_posterior <- tibble(rep = 1:5000) %>% 
  mutate(sims = map(rep, ~ simular_conjunta(.x, datos))) %>% 
  unnest(cols = sims)
sims_posterior
```

Y ahora podemos aproximar fácilmente la probabilidad de interés:

```{r}
sims_posterior %>% 
  group_by(rep) %>% 
  mutate(sabor = sabor[which.max(valor_sim)]) %>% 
  group_by(sabor) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(prop = n / sum(n))
```

Y vemos que los mejores sabores son mango y limón. La probabilidad posterior de
que mango sea el sabor preferido por la población es de 66%. La integral
correspondiente no es trivial.


```{block2, type='ejercicio'}

- ¿Cuáles son las probabilidades a priori de que cada sabor sea el preferido
por la población?
- ¿Cuál es la integral correspondiente a las probabilidades que acabamos de calcular?
  ¿Qué tan fácil es hacer esta integral de manera analítica?
- Calcula la probabilidad de que mango sea preferido a limón?
- ¿Qué conclusión práctica sacas de estos resultados?
  
```


## Integración Monte Carlo vía Cadenas de Markov {-}

Hasta ahora hemos visto que el método Monte Carlo nos ayuda a aproximar
integrales de manera numérica. Sin embargo, para que este método funcione
necesitamos poder simular muestras independientes de la distribución de interés.

Sin embargo, en aplicaciones como en inferencia bayesiana: 

- la distribución la conocemos módulo una constante de normalización. 
- la distribución no tiene una forma reconocible que corresponda a un
simulador estándar.
- ¿cómo podemos simular si sólo conocemos parcialmente la expresión analítica?

Podemos aproximar integrales de interés utilizando muestras correlacionadas, lo 
cual implica relajar el supuesto de independencia, y construir una secuencia de 
simulaciones que tengan como distribución límite la distribución que nos
interesa. Para ser completamente explícitos, lo que queremos es resolver problemas
del estilo 

$$\pi(f) = \int f(x) \,\, \pi(x) \,\, \text{d}x, $$

donde $\pi(x)$ es la función de densida de la variable aleatoria $x.$ 
Lo que necesitamos es generar una *secuencia* de puntos en el soporte de $x$ de 
tal forma que podamos utilizar 

$$\pi(f) \approx \frac1N \sum_{n= 1}^N f(u^{(n)}).$$

Lo que pedimos es que la secuencia tenga una correlación débil que expresamos 
a través de la propiedad Markoviana (cadena de Markov) para aproximar integrales
como si fuera el método Monte Carlo. Es decir, utilizamos integración Monte
Carlo vía Cadenas de Markov (MCMC por sus siglas en inglés).

### Fundamentos e ideas {-}

Implementar MCMC requiere de definir un mecanismo de muestreo (que llamamos
*kernel* Markoviano) que permita tener como distribución límite la distribución
objetivo $\pi$. De tal forma que podamos seguir aproximando $\pi(f)$ por medio de 

$$\pi(f) \approx \frac1N \sum_{n= 1}^N f(u^{(n)}).$$

Bajo ciertas condiciones de regularidad el estimador se vuelve *insesgado* y
satisface una versión del teorema de límite central para ciertas funciones $f.$
Estudiar el diseño y analisis de métodos de MCMC escapa a los objetivos del
curso pero pueden ser estudiados desde teorica ergódica [@mcmcStability]. 

#### Ejemplo: vendedor ambulante {-}

Por simplicidad, estudiaremos una clase de algoritmos que se denominan
Metropolis-Hastings dentro de toda la familia de MCMC. Primero veremos un
ejemplo para establecer un poco de intuición.

Supongamos que un nuevo vendedor de *Yakult* trabajará a lo largo de una cadena
de 5 islas:

* La idea que tiene es viajar constantemente entre las islas ofreciendo sus
productos;

* Al final de un día de trabajo decide si permanece en la misma isla o se 
transporta a una de las $2$ islas vecinas;

* El vendedor sólo tiene información local y no lleva un registro de cuántas
islas hay en el archipielago; sin embargo, una vez que se encuentra en una isla
puede investigar la población de la misma y también de la isla a la que se
propone viajar después.

* El objetivo del vendedor es visitar las islas de manera proporcional a la 
población de cada una. Con esto en mente el vendedor utiliza el siguiente 
proceso: 

    1) Lanza un volado, si el resultado es águila se propone ir a la isla 
del lado izquierdo de su ubicación actual y si es sol a la del lado derecho.
    2) Si la isla propuesta tiene población mayor a la población de la isla actual,
el vendedor decide viajar a ella. Si la isla vecina tiene población menor,
entonces visita la isla propuesta con una probabilidad que depende de la
proporción de la población de las islas. 

Es decir, en el $t-$ésimo día la decisión del vendedor es como sigue. Sea
$\pi^*$ la población de la isla propuesta y $\pi_{t}$ la población de la isla
actual. Entonces el vendedor cambia de isla con probabilidad

$$\alpha_{\textsf{mover}}= \frac{\pi^*}{\pi_{t}}$$
Nota que entre mas parecidas sean las poblaciones de las islas mas *indeciso*
será de moverse y además $\alpha_{\textsf{mover}} \in (0,1)$ por definición. De
hecho, podemos definir la probabilidad de viajar a otra isla por medio de

$$\alpha(t, *) = \min \Bigg\{ 1, \frac{\pi^*}{\pi_{t}}\Bigg\},$$

pues incluye los dos casos. 

A la larga, si el vendedor sigue la heurística anterior la probabilidad de que
el vendedor este en alguna de las islas coincide con la población relativa de
la isla. 

```{r, fig.height=6, fig.width=3.5}

set.seed(1087)

islas <- tibble(islas = 1:5, pob = 1:5)
camina_isla <- function(i){ # i: isla actual
    u <- runif(1) # volado
    v <- ifelse(u < 0.5, i - 1, i + 1)  # isla vecina (índice)
    if (v < 1 | v > 5) { # si estas en los extremos y el volado indica salir
      return(i)
    }
    u2 <- runif(1)
    p_move = min(islas$pob[v] / islas$pob[i], 1)
    if (p_move  > u2) {
        return(v) # isla destino
    }
    else {
      return(i) # me quedo en la misma isla
    }
}
pasos <- 100000
iteraciones <- numeric(pasos)
iteraciones[1] <- sample(1:5, 1) # isla inicial
for (j in 2:pasos) {
    iteraciones[j] <- camina_isla(iteraciones[j - 1])
}
caminata <- tibble(pasos = 1:pasos, isla = iteraciones)
plot_caminata <- ggplot(caminata[1:500, ], aes(x = pasos, y = isla)) +
    geom_point(size = 0.8) +
    geom_path(alpha = 0.5) +
    coord_flip() + 
    labs(title = "Caminata aleatoria") +
    scale_x_continuous(trans = "log10", "Tiempo", breaks = c(1, 2, 5, 20, 100, 500)) +
    scale_y_continuous( expression(theta))
plot_dist <- ggplot(caminata, aes(x = isla)) +
    geom_bar(fill = "darkgray", aes(y = (..count..)/sum(..count..))) +
    scale_x_continuous(expression(theta), breaks = 1:10) +
    labs(title = "Distribución objetivo", 
       y = expression(pi(theta)))
plot_caminata / plot_dist
```

Entonces:

* Para aproximar la distribución objetivo debemos permitir que el vendedor 
recorra las islas durante una sucesión larga de pasos y registramos sus visitas. 

* Nuestra aproximación de la distribución es justamente el registro de sus 
visitas. 

* Más aún, debemos tener cuidado y excluir la porción de las visitas que se 
encuentran bajo la influencia de la posición inicial. Esto es, debemos excluir 
el **periodo de calentamiento**. 

* Una vez que tenemos un registro _largo_ de los viajes del vendedor (excluyendo 
el calentamiento) podemos aproximar la distribución objetivo 
simplemente contando el número relativo de veces que el vendedor visitó
dicha isla.

```{r, warning=FALSE, message=FALSE, fig.width=8, fig.height=7.5}
t <- 4**(0:8)
plots_list <- map(t, function(i){
    ggplot(caminata[1:i, ], aes(x = isla)) +
        geom_bar(fill = "darkgray", aes(y = (..count..)/sum(..count..))) +
        labs(y = "", x = "", title = paste("t = ", i, sep = "")) +
        scale_x_continuous(expression(theta), breaks = 1:5, limits = c(0, 6))
})
wrap_plots(plots_list)
```

Escribamos el algoritmo, para esto indexamos las islas por el valor
$\theta$, es así que la isla del extremo oeste corresponde a $\theta=1$ y la 
población relativa de cada isla es $\pi(\theta)$:

1. El vendedor se ubica en una isla al tiempo $t$, lo cual denotamos por
$\theta^{(t)}$ y propone moverse a la izquierda o derecha $\theta^{(*)}$ con
probabilidad $0.5$. El rango de los posibles valores para moverse, y la
probabilidad de proponer cada uno se conoce como **distribución propuesta**, en
nuestro ejemplo sólo toma dos valores cada uno con probabilidad $0.5$.

2. Una vez que se propone un movimiento, decidimos si aceptarlo. La decisión de
aceptar se basa en el valor de la distribución **objetivo** en la posición
propuesta, relativo al valor de la distribución objetivo en la posición actual:
$$\alpha\left(\theta^{(t)}, \theta^{(*)}\right)=\min\bigg\{\frac{\pi(\theta^{(*)})}{\pi(\theta^{(t)})},1\bigg\},$$
donde $\alpha$ denota la probabilidad de hacer el cambio de isla. 

Notemos que la distribución objetivo $\pi(\theta)$ no necesita estar
normalizada, esto es porque lo que nos interesa es el cociente
$\pi(\theta^*)/\pi(\theta^{(t)})$.

3. Una vez que propusimos un movimiento y calculamos la probabilidad de aceptar
el movimiento, aceptamos o rechazamos el movimiento generando un valor de una
distribución uniforme, si dicho valor es menor a la probabilidad de cambio,
$\alpha,$ entonces hacemos el movimiento.

Entonces, para utilizar el algoritmo necesitamos ser capaces de:

* Generar un valor de la distribución propuesta en este caso es una decisión
binaria con probabilidad $0.5$.

* Evaluar la distribución objetivo en cualquier valor propuesto (para calcular
$\pi(\theta^{(*)})/\pi(\theta^{(t)})$).

* Generar un valor uniforme (para movernos con probabilidad $\alpha$).

Las $3$ puntos anteriores nos permiten generar muestras aleatorias de la
distribución objetivo, sin importar si esta está normalizada. Esta técnica es
particularmente útil cuando cuando la distribución objetivo la conocemos módulo
la constante de normalización. Como por ejemplo, en inferencia bayesiana cuando
tenemos $p(x|\theta)p(\theta)$ (en nuestra notación Bayesiana).

Para entender porque funciona el algoritmo anterior hace falta entender $2$
puntos, primero que la distribución objetivo es **estable** para el modelo de
transición. Esto lo verificamos cuando la probabilidad _actual_ de ubicarse en
una posición coincide con la probabilidad en la distribución objetivo, entonces
el algoritmo para generar los saltos preserva las probabilidades en el límite.

```{r, warning=FALSE, message=FALSE, fig.width=8, fig.height=7.5}
library(expm)
transMat <- function(P){ # recibe vector de probabilidades (o población)
    T <- matrix(0, 5, 5)
    n <- length(P - 1) # número de estados
    for (j in 2:n - 1) { # llenamos por fila
        T[j, j - 1] <- 0.5 * min(P[j - 1] / P[j], 1)
        T[j, j] <- 0.5 * (1 - min(P[j - 1] / P[j], 1)) + 
                   0.5 * (1 - min(P[j + 1] / P[j], 1))
        T[j, j + 1] <- 0.5 * min(P[j + 1] / P[j], 1)
    }
    # faltan los casos j = 1 y j = n
    T[1, 1] <- 0.5 + 0.5 * (1 - min(P[2] / P[1], 1))
    T[1, 2] <- 0.5 * min(P[2] / P[1], 1)
    T[n, n] <- 0.5 + 0.5 * (1 - min(P[n - 1] / P[n], 1))
    T[n, n - 1] <- 0.5 * min(P[n - 1] / P[n], 1)
    T
}
T <- transMat(islas$pob)
w <- c(0, 1, rep(0, 3))
t <- 4**(0:8)
expT <- map_df(t, ~data.frame(t = ., w %*% (T %^% .)))
expT_long <- expT %>%
    gather(theta, P, -t) %>% 
    mutate(theta = parse_number(theta))
ggplot(expT_long, aes(x = theta, y = P)) +
    geom_bar(stat = "identity", fill = "darkgray") + 
    facet_wrap(~ t) +
    scale_x_continuous(expression(theta), breaks = 1:5, limits = c(0, 6))
```

El segundo punto es que el proceso converge a la distribución objetivo. 
Podemos ver, (en nuestro ejemplo sencillo) que sin importar el punto de inicio
se alcanza la distribución objetivo.

```{r, warning=FALSE, message=FALSE, fig.width=8, fig.height=7.5}
inicio_p <- function(i){
    w <- rep(0, 5)
    w[i] <- 1
    t <- c(1, 10, 50, 100)
    exp_t <- map_df(t, ~ data.frame(t = .x, inicio = i, w %*% (T %^% .))) %>%
        gather(theta, P, -t, -inicio) %>% 
        mutate(theta = parse_number(theta))
    exp_t
}
exp_t <- map_df(c(1, 3, 5), inicio_p)
ggplot(exp_t, aes(x = as.numeric(theta), y = P)) +
    geom_bar(stat = "identity", fill = "darkgray") + 
    facet_grid(inicio ~ t) +
    scale_x_continuous(expression(theta), breaks = 1:5, limits = c(0, 6))
```

## El método Metropolis-Hastings {-}

Ahora formalicemos lo que hicimos con nuestro vendedor ambulante. 
El algoritmo necesita dos ingredientes: *una generador de saltos* $q(u, v),$ que 
es el *kernel* de transición; y una probabilidad de aceptación $\alpha(u,v),$
que convierte el *kernel* de transición en un *kernel* que preserva la
distribución objetivo $\pi.$ 

En el ejemplo del vendedor de *Yakults* no sólo bastaba con seleccionar de las
islas vecinas al azar. También es importante que la transición se haga de manera
relativa a las poblaciones. La conjunción de ambas es lo que permite la
construccion de una cadena ergódica.

Usando estos dos elementos hacemos lo siguiente. Partiendo de la $n-$ésima
iteración localizada en $u^{(n)}$, generamos un candidato $u^{(*)}$ por medio de

$$u^{(*)} \sim q(u^{(n)}, \,\cdot\,),$$

y aceptamos el salto con probabilidad $\alpha(u^{(n)}, u^{(*)})$ donde la 
probabilidad de aceptación de salto está dada por 

$$\alpha(u^{(n)}, u^{(*)}) = \min \bigg\{ \frac{\pi(u^{(n)})}{\pi(u^{(*)}) } \cdot \frac{q(u^{(n)}, u^{(*)})}{q(u^{(*)}, u^{(n)})}, \, 1\bigg\}.$$

```{block, type = 'comentario'}

- Lo que necesitamos para poder implementar el Metropolis-Hastings es poder
simular de manera independiente del *kernel* propuesta $q(u, \cdot)$ para
cualquier valor de $u.$

- Del cálculo de la probabilidad de aceptación podemos ver que si sólo conocemos la 
densidad módulo una constante de normalización, ¡no importa! Pues el cociente 
$\pi(u)/\pi(v)$ cancela la constante. 

- El método se puede simplificar bastante si consideramos propuestas simétricas.
Es decir, $q(u,v) = q(v, u).$ En este caso podemos notar que el método aceptará
transiciones de manera *automática* a zonas de alta densidad, y con un
movimiento aleatorio a zonas de menor densidad.

- El algoritmo es bastante flexible para escoger $q(u, v),$ sin embargo, el 
comportamiento ergódico dependerá en gran medida de esta elección.

- Aceptar con probabilidad $\alpha$ se puede simular por medio de una variable
aleatoria $\phi \sim \mathsf{U}[0,1].$ Si $phi \in [0, \alpha)$ entonces la 
propuesta se acepta ($u^{(n+1)} = u^*$); se rechaza en caso contrario
($u^{(n+1)} = u^{(n)}$).

```

Una elección común es escoger $q(u, v)$ como una $\mathsf{N}(u, \sigma^2)$.
Donde el parámetro $\sigma^2$ se ajusta para tener un comportamiento deseado.
Mas adelante veremos formas de establecer diágnosticos de interés.

Ilustraremos con un caso artificial

```{r}
crear_metropolis <- function(fun_log, sigma_salto = 0.1){
  # fun_log es la funcion objetivo en escaa logaritmica
  # sigma_salto es la varianza de los saltos en la propuesta
  iterar_metropolis <- function(theta_inicial, n){
    p <- length(theta_inicial)
    nombres <- names(theta_inicial)
    iteraciones <- matrix(0, nrow = n, ncol = p)
    colnames(iteraciones) <- nombres
    iteraciones[1,] <- theta_inicial
    for(i in 2:n){
      theta <- iteraciones[i - 1, ]
      theta_prop <- theta + rnorm(p, 0, sigma_salto)
      # exp(log(p) - log(q)) = p/q
      cociente <- exp(fun_log(theta_prop) - fun_log(theta))
      if(cociente >= 1 || runif(1,0,1) < cociente){
        iteraciones[i, ] <- theta_prop
      } else {
        iteraciones[i, ] <- theta  
      }
    }
    iteraciones_tbl <- iteraciones %>% 
      as_tibble() %>%  
      mutate(iter_num = row_number()) %>% 
      select(iter_num, everything())
    iteraciones_tbl
  }
  iterar_metropolis
}
```

e intentamos simular de una exponencial no normalizada:

```{r}
exp_no_norm <- function(x) {
  z <- ifelse(x > 0, exp(-0.5 * x), 0)
  log(z)
}

iterador_metro <- crear_metropolis(exp_no_norm, sigma_salto = 0.5)
sims_tbl <- iterador_metro(c(theta = 0.5), 10000)
g_exp_mh <- ggplot(sims_tbl, aes(x = theta)) + 
  geom_histogram(aes(y = ..density..)) + 
  xlim(0, 20) + ggtitle("Metropolis-Hastings")

g_exp_rexp <- tibble(theta = rexp(10000, rate = .5)) %>% 
  ggplot(aes(x = theta)) + 
  geom_histogram(aes(y = ..density..)) + 
  xlim(0, 20) + ggtitle("rexp")

g_exp_mh + g_exp_rexp
```

Ahora probemos con una $\mathsf{Beta}(3, 2):$

```{r}
beta_no_norm <- function(x) {
  z <- ifelse(x > 0 && x < 1, (x^2)*(1-x), 0)
  log(z)
}

iterador_metro <- crear_metropolis(beta_no_norm, sigma_salto = 0.04)
sims_metro_tbl <- iterador_metro(c(theta = 0.5), 50000)
sims_indep_tbl <- tibble(iter_num = 1:30000, theta = rbeta(30000, 3, 2))
g_1 <- ggplot(sims_metro_tbl, aes(x = theta)) + 
  geom_histogram(aes(y = ..density..)) +
  labs(subtitle = "Metropolis-Hastings")
g_2 <- ggplot(sims_indep_tbl, aes(x = theta)) + 
  geom_histogram(aes(y = ..density..)) +
  labs(subtitle = "rbeta")
g_1 + g_2
```
y vemos que esto funciona.

Nótese un aspecto de estas simulaciones que no habíamos encontrado en el curso.
Aunque la distribución final de las simulaciones es muy cercana a la de la
distribución que queremos simular, lo cual era nuestro propósito, las
**simulaciones no son extracciones independientes** de esa distribución.

La construcción del algoritmo muestra eso, pero podemos también graficar las
simulaciones:

```{r, fig.width = 8}
g_metropolis <- sims_metro_tbl %>% 
  filter(iter_num < 500) %>% 
  ggplot(aes(x = iter_num, y = theta)) +
  geom_line() + labs(subtitle = "Metropolis-Hastings")
g_indep <- sims_indep_tbl %>% 
  filter(iter_num < 500) %>% 
  ggplot(aes(x = iter_num, y = theta)) +
  geom_line() + labs(subtitle = "Independientes")
g_metropolis + g_indep
```

Donde vemos claramente que las simulaciones de Metropolis-Hastings están
autocorrelacionadas: la siguiente simulación depende de la anterior. Esto define
una cadena de Markov.

En cualquiera de los dos casos, como vimos en los histogramas de arriba, las
simulaciones "visitan" cada parte [0,1] de manera proporcional a la densidad, de
manera que podemos usar ambos tipos de simulaciones para aproximar la integral o
cantidad que nos interesa. Por ejemplo, la media posterior es:

```{r}
media_1 <- sims_metro_tbl %>% summarise(media_post = mean(theta)) %>% pull(media_post)
media_2 <- sims_indep_tbl %>% summarise(media_post = mean(theta)) %>% pull(media_post)
media_exacta <- 3/(3 + 2)
tibble(metodo = c("sim Metropolis-Hastings", "sim Independiente", "exacto"),
       media_post = c(media_1, media_2, media_exacta))
```

**Observaciones**: 

1. Aunque hay distintas *condiciones de regularidad* que pueden funcionar,
generalmente el supuesto es que la cadena de Markov construída es
[ergódica](https://en.wikipedia.org/wiki/Ergodic_theory), y hay varias
condiciones que garantizan esta propiedad. Una condición simple, por ejemplo, es
que el soporte de la distribución $\pi(\theta)$ es un conjunto conexo del espacio
de parámetros.

2. Más crucialmente, este resultado no dice qué tan grande debe ser $N$ para que
la aproximación sea buena. Esto depende de cómo es $\pi(\theta)$, y de la
distribución que se utiliza para obtener los saltos propuestos. Dependiendo de
estos dos factores, la convergencia puede ser rápida (exponencial) o tan lenta
que es infactible usarla. Más adelante veremos diagnósticos para descartar los
peores casos de falta de convergencia.

3. El método Metropolis-Hastings con propuestas simétricas se conoce como el
método de Metropolis. Aunque en nuestra exposición parece que Metropolis se
deriva de Metropolis-Hastings. Lo contrario pasó en la literatura. Pimero fue
formalizado el método de Metropolis en [@metropolis] y luego extendido a lo que
conocemos como Metropolis-Hastings en [@hastings].

## Ajustando la distribución de propuesta {-}

En el algoritmo Metrópolis, generalmente es importante escoger la 
dispersión de la distribución que genera propuestas con cuidado. 

- Si la dispersión de la propuesta es demasiado grande, tenderemos a rechazar mucho,
y la convergencia será lenta.
- Si la dispersión de la propuesta es demasiado chica, tardaremos mucho tiempo
en explorar las distintas partes de la distribución objetivo.

### Ejemplo {-}

Supongamos que queremos simular usando metróplis de una distribución 
$\textsf{Gamma}(20, 100)$. Abajo vemos la forma de esta distribución:

```{r}
sim_indep <- tibble(theta = rgamma(10000, 20, 100))
ggplot(sim_indep, aes(x = theta)) + geom_histogram()
```

```{r}
# logaritmo de densidad no normalizada
log_f_dist <- function(x) 210 + dgamma(x, 20, 100, log = TRUE)
# iterar
iterador_metro_chico <- crear_metropolis(log_f_dist, sigma_salto = 0.001)
sims_chico_tbl <- iterador_metro_chico(c(theta = 0.02), 50000)
g_sim <- ggplot(sims_chico_tbl %>% filter(iter_num < 3000), 
                aes(x = iter_num, y = theta)) + 
  geom_line() + 
  ylim(c(0, 0.5))

dist_bplot <- ggplot(tibble(x = rgamma(10000, 20, 100)), 
                     aes(y = x, x = "a")) + 
  geom_violin() + 
  ylab("") + 
  ylim(0, 0.5)

g_sim + dist_bplot + plot_layout(widths = c(5, 1))
```

Nótese que después de 5 mil iteraciones estamos muy lejos de tener una muestra
que se aproxime a la distribución objetivo. Empezamos en un lugar bajo, y la
cadena sólo ha ido lentamente hacia las zonas de alta densidad. *Cualquier
resumen con esta cadena estaría fuertemente sesgado* al valor donde iniciamos la
iteración. Decimos que la cadena todavía no *mezcla* en las primeras 5 mil
iteraciones.

Ahora vemos qué pasa si ponemos el tamaño de salto demasiado grande:

```{r}
set.seed(831)
iterador_metro_grande <- crear_metropolis(log_f_dist, sigma_salto = 20)
sims_grande_tbl <- iterador_metro_grande(c(theta = 0.02), 50000)

g_sim <- ggplot(sims_grande_tbl %>% filter(iter_num < 3000), 
                aes(x = iter_num, y = theta)) + 
  geom_line() + 
  ylim(c(0, 0.5))

g_sim + dist_bplot + plot_layout(widths = c(5, 1))
```

En este caso, la cadena se *atora* muchas veces, pues las propuestas tienen
probabilidad muy baja, y tendemos a tener una tasa de rechazos muy alta. Esto
quiere decir que la información que tenemos acerca de la posterior es
relativamente poca, pues muchos datos son repeticiones del mismo valor.
*Cualquier resumen con esta cadena podría estar muy lejos del verdadero valor,*
pues su varianza es alta - otra corrida se "atoraría" en otros valores
distintos.

Nótese que cualquiera de estas cadenas, si la corremos suficientemente tiempo,
nos daría resultados buenos. Sin embargo, el número de simulaciones puede ser
infactible.

Un valor intermedio nos dará mucho mejores resultados:

```{r}
set.seed(831)
iterador_metro_apropiada <- crear_metropolis(log_f_dist, sigma_salto = 0.1)
sims_tbl <-iterador_metro_apropiada(c(theta = 0.02), 50000)
g_sim <- ggplot(sims_tbl %>% filter(iter_num < 3000), 
  aes(x = iter_num, y = theta)) + geom_line() + ylim(c(0, 0.5))
g_sim + dist_bplot + plot_layout(widths = c(5, 1))
```
Donde vemos que esta cadena parece mezclar bien (está explorando la totalidad
de la distribución objetivo), y también parece estar en un estado estable.

Comparemos cómo saldría por ejemplo la media posterior aproximada según 
los tres métodos:

```{r}
estimaciones_media <- map_dfr(
  list(sims_chico_tbl, sims_grande_tbl, sims_tbl), 
  ~ filter(.x, iter_num < 3000) %>% 
    summarise(media = mean(theta))) %>% 
    mutate(tipo = c("salto chico", "salto grande", "salto apropiado"))
estimaciones_media %>% bind_rows(tibble(tipo = "exacta", media = 20/100)) %>% 
  select(tipo, media)
```

Veamos otra corrida:

```{r}
set.seed(6222131)
sims_chica_tbl <- iterador_metro_chico(c(theta = 0.02), 5000)
sims_grande_tbl <- iterador_metro_grande(c(theta = 0.02), 5000)
estimaciones_media <- map_dfr(
    list(sims_chica_tbl, sims_grande_tbl, sims_tbl), 
    ~ filter(.x, iter_num < 3000) %>% 
  summarise(media = mean(theta))) %>% 
  mutate(tipo = c("salto chico", "salto grande", "salto apropiado"))
estimaciones_media %>% bind_rows(tibble(tipo = "exacta", media = 20/100)) %>% 
  select(tipo, media)
```

```{block, type='ejercicio'}
Repite este proceso varias veces. Verifica que:

  - Si el tamaño de paso es muy chico, las estimaciones de la media tienen sesgo alto.
  - Si el tamaño de paso es muy grande, las estimaciones tienen varianza alta.
  - Si el tamaño de paso es adecuado, obtenemos buena precisión en la estimación de la media posterior.
  - Explica estos tres casos en términos de la convergencia de las realizaciones
    de la cadena de Markov. Explica cómo afecta a cada caso el valor inicial de las
    simulaciones de Metrópolis.
  - Repite para otra estadística, como la desviación estándar o el rangon intercuartil.
```

## Metropolis con varios parámetros {-}

Ahora aplicaremos el algoritmo Metrópolis cuando tenemos varios parámetros. La
idea es la misma, pero nuestra distribución de salto debe ser multivariada. Una
selección usual es usando saltos normales independientes para cada parámetro, es
decir, la normal multivariada con matriz de varianza y covarianza diagonal.

### Ejemplo: el modelo normal {-}

Veremos cómo simular con Metropolis para el problema de los cantantes. 
Sabemos como calcular la posterior:

```{r}
crear_log_posterior_norm <- function(x = datos, m_0, n_0, a, b){
  # calcula log_posterior
  log_posterior <- function(mu, sigma){
      log_verosim <- sum(dnorm(x, mu, sigma, log = TRUE))
      tau <- 1 / sigma^2
      log_inicial <- 
        dgamma(tau, a, b, log = TRUE) + 
        dnorm(mu, mu_0, sigma/sqrt(n_0), log = TRUE)
      log_p <- log_verosim + log_inicial
      log_p
  }
  log_posterior
}
```


```{r}
# parametros de inicial y datos
a <- 3
b <- 140
mu_0 <- 175
n_0 <- 5
set.seed(3413)
cantantes <- lattice::singer %>% 
  mutate(estatura_cm = round(2.54 * height)) %>% 
  filter(str_detect(voice.part, "Tenor")) %>% 
  sample_n(20)
```

Vemos cómo se ven las primeras iteraciones de nuestra cadena de Markov:

```{r}
log_p <- crear_log_posterior_norm(cantantes$estatura_cm, mu_0, n_0, a, b) 
log_post <- function(pars) { log_p(pars[1], pars[2]) }
set.seed(823)
metro_normal <- crear_metropolis(log_post, sigma_salto = 0.5)
sim_tbl <- metro_normal(c(mu = 172, sigma = 3), 50000) 
ggplot(sim_tbl %>% filter(iter_num < 100), 
       aes(x = mu, y = sigma)) + 
  geom_path() +
  geom_point()
```

Y ahora vemos todas las simulaciones:

```{r}
g_normal <- ggplot(sim_tbl, aes(x = mu, y = sigma)) + 
  geom_point(alpha = 0.05)+ coord_equal() + ylim(c(0, 14))
g_normal
```

Y las medias posteriores son:

```{r}
sim_tbl %>% summarise(across(is_double, mean))
```

### Ejemplo: observaciones normales, no conjugado {-}

Arriba repetimos el análisis conjugado usando Metrópolis. Aunque 
ya no es necesario usar el modelo conjugado, y podemos poner
iniciales que sean más intuitivas y acorde con nuestro conocimiento
existente.

Por ejemplo, podemos poner $p(\mu, \sigma) = p(\mu)p(\sigma)$, donde la densidad
de $\mu \sim \mathsf{N}(175, 2)$ y $\sigma \sim \mathsf{U}[2, 20].$ Igual que
antes, la verosimilitud $p(x|\mu, \sigma)$ es normal con media $\mu$ y
desviación estándar $\sigma.$

Escribimos la posterior:

```{r}
crear_log_posterior <- function(x, m_0, sigma_0, inf, sup){
  # calcula log_posterior
  log_posterior <- function(mu, sigma){
      log_verosim <- sum(dnorm(x, mu, sigma, log = TRUE))
      log_inicial <- 
        dunif(sigma, inf, sup, log = TRUE) + 
        dnorm(mu, mu_0, sigma_0, log = TRUE)
      log_p <- log_verosim + log_inicial
      log_p
  }
  log_posterior
}
```

```{r}
log_p <- crear_log_posterior(cantantes$estatura_cm, 175, 3, 2, 20) 
log_post <- function(pars) { log_p(pars[1], pars[2]) }
```


```{r, fig.width = 7}
set.seed(8231)
metro_normal <- crear_metropolis(log_post, sigma_salto = 0.5)
sim_tbl <- metro_normal(c(mu = 172, sigma = 5), 50000) 
g_normal_2 <- ggplot(sim_tbl, aes(x = mu, y = sigma))  +
  geom_point(alpha = 0.05) + coord_equal() + ylim(c(0, 14))
g_normal + g_normal_2
```
Los resultados son similares, pero en 
nuestras estimaciones bajo el segundo modelo, la $\sigma$ está
concentrada en valores un poco más bajos que el modelo normal-gamma inversa.
Las medias posteriores son:

```{r}
sim_tbl %>% summarise(across(is.numeric, mean))
```

Nótese que la inicial para el modelo normal-gamma inversa pone muy poca
probabilidad para valores bajos de $\sigma$, mientras que el segundo
modelo hay un 10% de probabilidad de que la $\sigma$ sea menor que 4.

```{r}
tau <- rgamma(5000, 3, 150)
sigma <- 1/sqrt(tau)
quantile(sigma, c(0.01,0.1, 0.9, 0.99))
quantile(runif(5000, 2, 25), c(0.01,0.1, 0.9, 0.99))
```



### Ejemplo: exámenes {-}

Recordamos un ejemplo que vimos en la sección de máxima verosimilitud.
Supongamos que en una población de estudiantes tenemos dos tipos: unos llenaron
un examen de opción múltiple al azar (1 de 5), y otros contestaron las
preguntas intentando sacar una buena calificación. Suponemos que una vez que
conocemos el tipo de estudiante, todas las preguntas tienen la misma
probabilidad de ser contestadas correctamente, de manera independiente. El
modelo teórico está representado por la siguiente simulación:

```{r}
sim_formas <- function(p_azar, p_corr){
  tipo <- rbinom(1, 1, 1 - p_azar)
  if(tipo==0){
    # al azar
    x <- rbinom(1, 10, 1/5)
  } else {
    # no al azar
    x <- rbinom(1, 10, p_corr)
  }
  x
}
```

Y una muestra se ve como sigue:

```{r}
set.seed(12)
muestra <- map_dbl(1:200, ~ sim_formas(0.35, 0.5))
qplot(muestra, geom = 'bar')
```

Supongamos que no conocemos la probabildad de contestar correctamente  ni la
proporción de estudiantes que contestó al azar. ¿Como estimamos estas dos cantidades?

La verosimilitud la escribimos en el ejercicio anterior en la sección de máxima verosimilitud, está dada, para las repuestas de un estudiante, por:

$$p(X = k|\theta_{azar}, \theta_{corr}) \propto \theta_{azar}(1/5)^k(4/5)^{10-k} +
(1-\theta_{azar})\theta_{corr}^k(1-\theta_{corr})^{10-k}$$

Suponiendo que todas las preguntas tienen la misma dificultad, y que
los estudiantes que estudiaron son homogéneos (podemos discutir qué haríamos
para introducir heterogeneidad que típicamente observaríamos).

Creemos que la mayoría de los estudiantes no contesta al azar, así que pondremos
como inicial

$$\theta_{azar} \sim \mathsf{Beta}(1, 5)$$

```{r}
qbeta(c(0.1, 0.9), 1, 5) %>% round(2)
```
Ahora tenemos que pensar en la probabilidad $\theta_{corr}$ para los estudiantes
que sí estudiaron. Imaginemos que lo probamos con un estudiante que
sabemos que sí estudió, y obtuvo un porcentaje de correctos de 7/10, Podríamos
poner entonces (vimos 10 intentos, con 3 fracasos y 7 éxitos):

$$\theta_{corr} \sim \mathsf{Beta}(7, 3)$$
Finalmente, necesitamos la conjunta inicial. Pondremos
$$p(\theta_{azar},\theta_{corr}) = p(\theta_{azar})p(\theta_{corr})$$
con lo que expresamos que inicialmente no creemos que estos dos parámetros estén
relacionados. Si pensáramos, por ejemplo, que cuando hacemos exámenes difíciles
menos estudiantes estudian, entonces deberíamos intentar otra conjunta.

Escribimos el producto de la verosimilitud con la inicial:

```{r}
crear_log_posterior <- function(x){
 
  log_posterior <- function(theta_azar, theta_corr){
    log_verosim <- sum(log(theta_azar * dbinom(x, 10, 1/5) + 
                          (1 - theta_azar) * dbinom(x, 10, theta_corr)))
    log_inicial <- dbeta(theta_azar, 1, 5, log = TRUE) +
      dbeta(theta_corr, 7, 3, log = TRUE)
    log_post <- log_verosim + log_inicial
    log_post
  }  
  log_posterior

}
```

Creamos la función de verosimilitud con los datos

```{r}
log_p <- crear_log_posterior(muestra)
log_post <- function(pars) { log_p(pars[1], pars[2]) }
set.seed(8231)
metro_examenes <- crear_metropolis(log_post, sigma_salto = 0.02)
sim_tbl <- metro_examenes(c(theta_azar = 0.5, theta_corr = 0.5), 20000)
g_1 <- ggplot(sim_tbl, aes(x = theta_azar, y = theta_corr))  +
  geom_point(alpha = 0.05) + coord_equal() 
g_1
```

Nótese que hay cierta correlación entre las dos proporciones, y esto produce
intervalos posteriores relativamente amplios. Esto es de esperarse, pues
los datos son consistentes con una proporción relativamente chica de
estudiantes que contestan al azar, y tasas de correctos más altas entre los
que sí estudian, y una proporción más grande de respuestas al azar con
tasas de correctos más altas.

```{r}
f <- c(0.05, 0.5, 0.95)
sim_tbl %>% 
  pivot_longer(-iter_num, names_to = "parametro", values_to = "valor") %>% 
  group_by(parametro) %>% 
  summarise(cuantil = quantile(valor, f), f = f) %>% 
  mutate(cuantil = round(cuantil, 2)) %>% 
  pivot_wider(names_from = f, values_from = cuantil)
```


## Conclusiones y observaciones {-}

* El método de Metropolis-Hastings es muy flexible y existe una colección
numerable de versiones diferentes que pueden ser empleadas en contextos muy
particulares. Una buena referencia que incluye métodos de simulación por medio
de cadena de Markov se encuentra en [@liuMonte], donde incluso se pueden 
encontrar generalizaciones con *kernels* asimétricos. 


* [JAGS](http://mcmc-jags.sourceforge.net) (Just Another Gibbs Sampler), WinBUGS
y OpenBUGS son programas que implementan métodos MCMC para generar simulaciones 
de distribuciones posteriores. Los paquetes `rjags` y `R2jags` permiten ajustar 
modelos en JAGS desde `R`. Es muy fácil utilizar estos programas pues uno 
simplemente debe especificar las distribuciones iniciales, la verosimilitud y 
los datos observados. Para aprender a usar JAGS se puede revisar la sección 
correspondiente en las [notas de 2018](https://tereom.github.io/est-computacional-2018/jags.html),
ahora nos concentraremos en el uso de Stan.


## Simulación por sistema Hamiltoniano {-}

> It appears to be quite a general principle that, whenever there is a 
randomized way of doinf something, then there is a nonrandomized way that 
delivers better performance but requires more thought. -E.T. Jaynes

`Stan` es un programa para generar muestras de una distribución posterior de los
parámetros de un modelo, el nombre del programa hace referencia a [Stanislaw
Ulam (1904-1984)](https://en.wikipedia.org/wiki/Stanislaw_Ulam) que fue pionero
en los métodos de Monte Carlo. A diferencia de JAGS y BUGS, los pasos de la
cadena de Markov se generan con un método llamado *Monte Carlo Hamiltoniano*
(HMC). HMC es computacionalmente más costoso que Metrópolis o Gibbs, sin
embargo, sus propuestas suelen ser más eficientes, y por consiguiente no
necesita muestras tan grandes. En particular cuando se ajustan modelos grandes y
complejos (por ejemplo, con variables con correlación alta) HMC supera a otros.





